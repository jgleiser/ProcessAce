# Server Configuration
PORT="3000"
NODE_ENV="development"
LOG_LEVEL="info"

# LLM Configuration
# Required for real generation:
LLM_API_KEY="sk-your-openai-key-here"
LLM_MODEL="gpt-3.5-turbo"

# Optional: Override URL for local LLMs (e.g., Ollama, LocalAI)
# LLM_PROVIDER_URL=http://localhost:11434/v1

# Dev/Testing
# Set to 'true' to use the internal mock provider (generates dummy BPMN without calling an API)
MOCK_LLM="false"
